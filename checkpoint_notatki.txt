main wola cr_checkpoint z PID i adresem args typu cr_checkpoint_args

ustalanie cr_checkpoint_args:
outfs -> dostaje fd STDOUT
logfd -> makro CHECKPOINT_FD_NONE, jezeli --logfile podano to logfd dostaje jego deskryptor (tworzony jest plik)
uerrfd -> dostaje STDERR

cr_checkpoint
sprawdza czy args->container zawiera wartosc. Jezeli tak to args->flags dostaje dodatkowa flage CHECKPOINT_SUBTREE

wolany jest sys_checkpoint, ktory wola do_sys_checkpoint z parametrami: pid, args->outfd, args->flags, args->logfd

do_sys_checkpoint

tworzony sobie wskaznik struktury ckpt_ctx o nazwie ctx

jezeli flags nie zawiera CHECKPOINT_USER_FLAGS zwraca blad
jezeli uprawnienia nie sa na poziome CAP_SYS_ADMIN zwraca blad
jezeli pid==0 to pobiera pid taska current (current to makro - juz jestesmy w kernelu)
ctx jest allokowane uzywajac fd (dawne outfd) flags (dawne flags) CKPT_CTX_CHECKPOINT oraz logfd (dawne logfd). Ta alokacja MUSI sie udac inaczej ctx jest NULL i zwracamy blad.

wolany jest do_checkpoint z ctx i wartoscia pid. Jezeli ta funkcja zwroci blad kod bledu zawiera ctx->crid.
Wolana jest funkcja ckpt_ctx_put na ctx - czyzby zwalniala pamiec zajmowana przez ctx?

cpkt_ctx_alloc( fd, flags -> uflags, CKPT_CTX_CHECKPOINT -> kflags, logfd)
tworzy strukture ckpt_ctx ctx i wypelnia ja zerami
ctx->uflags=uflsgs;
ctx->kflags=kflags;
ctx->ktime_begin = ktime_get();
atimic_sec ustawia &ctx->refcount na 0
inicjacja list_head (makra INIT_LIST_HEAD) w ctx->pgarr_list oraz ctx->pgarr_pool
inicjacja waitqueue (makra init_waitqueue_head) na ctx->waitq oraz ctx->ghostq
init_completion (???) na ctx->complete oraz ctx->errno_sync
jezeli zdefiniowano CONFIG_CHECKPOINT_DEBUG to dodatkowo INIT_LIST_HEAD na ctx->task_status oraz wolamy spin_lock_init na ctx->lock

wolamy mutex_init na ctx->msg_mutex

INIT_LIST_HEAD na ctx->listen_sockets
ctx->file fostaje wynik fget(fd) (???)

ctx->file nie moze byc NULL bo inaczej blad
jezeli ctx->logfile == NULL blad. Moze byc natomiast CHECKPOINT_FS_NONE. Inaczej jego wartosc ustala fget(logfd)
tworzenie deferqueue na ctx->deferqueue oraz ctx->files_deferq
ctx->scratch_page dostaje przerzutowany na void* wynik __get_free_page(GFP_KERNEL) (????)
atomic_inc zwieksza ctx->refcount
ckpt_ctx_alloc zwraca adres ctx

DO_CHECKPOINT( *ctx, pid)
wolany jest init_checkpoint_ctx(ctx,pid), wynik dostaje long ret
jezeli ctx->root_freezer to wolana jest fukncje cgroup_freezer_begin_checkpoint (nie interesujacy przypadek bo nei widzialem abyu gdzie to bylo ustawiane)
build_tree(ctx) a wynik do ret
jezeli ctx->uflags zawiera CHECKPOINT_SUBTREE to wolane sa: connect_object(ctx) a wynik leci do ret; 
jezeli ret >=0 to sprawdzamy czy ckpt_obj_contained zwraca true. Inaczej blad (w obu ifach)
teraz wolane sa kolejno: checkpoint_write_header, checkpoint_container, checkpoint_pids, checkpoint_tree, checkpoint_all_tasks z parametrem ctx. Wyniki leca do ret i po kazdej funkcji sprawdzamy czy ret < 0. Jezeli ret <0 to mamy blad
wolamy deferqueue_run na ctx->deferqueue
jezeli ckpt_obj_visited(ctx) zwraca false
wywolaj checkpoint_write_tail(ctx)
UWAGA w przypadku bledu ctx->crid dostaje wynik atomic_inc_return(&ctx_count)

INIT_CHECKPOINT_CTX(ctx,pid)
uzywamy task typu task_struct*, nsproxy typu nsproxy*, fs typu fs_struct*
rcu_read_lock i rcu_read_unlock a pomiedzy tymi funkcjami task dostaje wynik find_task_by_vpid(pid). Jezeli task nie jest NULL to wolamy get_task_struct(task).
Jezeli teraz task to NULL to zwracamy blad. Inaczej ctx->root_task = task
Znow rcu_read_lock i rcu_read_unlock ale teraz nsproxy kolejno: nsproxy = task_nsproxy(task). Jezeli nsproxy nie jest NULL to get_nsproxy(nsproxy)
jezeli nsproxy NULL to return blad inaczej ctx->nsproxy = nsproxy
ctx->root_freezer dostaje get_freezer(task)
ctx->root_init dostaje is_container_init(task);
jezeli nie (ctx->uflags zawiera CHECKPOINT_SUBTREE i ctx->root_init jest NULL) -> blad
task_lock(cts->root_task);
fs = ctx->root_task->fs;
spin_lock(&fs->lock);
ctx->root_fs_path = fs->root;
path_get(&ctx->root_fs_path);
spin_unlock(&fs->lock);
task_unlock(ctx->root_task);

BUILD_TREE(ctx)
int n,m

n = tree_count_tasks(ctx) // ciekawe jak on to liczy
// z komentarzy wynika, ze jezeli cts->tasks_arr jest NULL to tylko policzy ich ilosc, jezeli nie jest null to ja wypelni
ctx->nr_tasks = n
ctx->tasks_arr = kzalloc(n * sizeof(*ctx->tasks_arr), GFP_KERNEL)

m = tree_count_tasks(ctx) //tym razem dodatkowo wypelni tablice
jezeli m<0 lub (m>0 i m!=n) <- blad

TREE_COUNT_TASKS(ctx)
przeglad zadan wedlug tasks_arr (zaczynajac od cts->tsk). sprawdzana jest funkcja may_checkpoint(ctx, task). Ta funkcja chyba sprawdza czy zadanie jest zamrozone.

CHECKPOINT_WRITE_HEADER(struct ckpt_ctx *ctx)
nadglowek ma typ ckpt_hdr_header i jest pobrany przez ckpt_hdr_get_type(ctx, sizeof(*h), CKPT_HDR_HEADER). struktura h jest potem uzupelniana kilkoma stalymi. Ciekawy moze buc zapis fill_kernel_const(&h->constants). sam zapis uzywa cpkt_write_obj i ckpt_hdr_put. Byc moze ciekawa moze okaze sie jeszcze funckja checkpoit_write_header_arch

CHECKPOINT_CONTAINET(ckpt_ctx *ctx)
Ciekawe bo znow pojawia sie nadglowek ale tym razem kontenerka? Zwrot kodu funkcji to wynik security_checkpoint_header(ctx).

CHECKPOINT_PIDS(struct ckpt_ctx *ctx)
tworzona jest tablica wypelniana czyms? tableta pids_arr typu flex_array. Jest tez nadglowek typu ckpt_hdr_pids. Uzupelnianie robi funkcja checkpoint_pids_build teorie te opieram na tym, ze funkcja ta zwraca jakies liczby do nr_pids i nr_vpids typu int. Jest jeszcze checkpoint_pids_dump, ktora dokonuje faktycznego zapisu do ctx?

CHECKPOINT_TREE(struct ckpt_ctx *ctx)
nie ciekawa robi strukture dla NS i drzewa pidow

CHECKPOINT_ALL_TASKS
wola w petli checkpoint_task

CHECKPOINT_TASK
zwraca kod bledu? parametry to wskaznik ctx typu cpkt_ctx oraz wskaznik t typu task_struct
calosc skupia sie na wolaniu checkpoint_task_struct, checkpoint_thread, checkpoint_restart_block, checkpoint_cpu, checkpoint_task_objs oraz checkpoint_task_signal. Jezeli ktoraz z tych funkcji zwroci blad to zapisanie stanu sie nie udalo.

CHECKPOINT_TASK_STRUCT
funkcja zapisuje kawalek task_struct. Oto pola jakie zapamietujemy:
flags
state
exit_state
exit_code
sas_ss_sp
sas_ss_size
exit_signal
pdeath_signal
set_child_tid
clear_child_tid
Wolanie jest jeszcze makro? save_task_robust_futex_list(h, t) <-- t zapisujemy a h to struktura do ktorej zapisujemy (tutaj typu cpkt_hdr_task)
Uwaga: pole flag moze byc uzypelniane o flagi: CKPT_PF_FORKNOEXEC lub CKPT_PF_SUPERPRIV. Dodatkowo jezeli t->exit_state != EXIT_ZOMBIE wolane jest BUG_ON.

CHECKPOINT_THREAD
Zalezy od ARCH
Najpierw wola may_checkpoint_thread, ktory ocenia czy mozna zrobic checkpoint. Mozna ja uzyc ale potrzem trzeba sprawdzic czy da sie ja uzupelnic o debugregs (?).
samo checkpoint_thread tez wyglada obiecujaco - do uzycia

CHECKPOINT_RESTART_BLOCK
ta funkcja to hardcore. Pobiera stack i rzutuje go na thread_info (zalezne od ARCH). Nastepnie z tej dtruktury pole restart_block trafia do zmiennej restart_block (lokalnej dla funkcji). Dzieki temu mozna sprawdzic co zaweira wskaznik restart_block->fn. Porownujemy kilka adresow funkcji. Nie wiem jeszcze po co ale sa one zmiazane ze sposobem liczenia czasu?
Nadal nie wiem jak to sie ma do dzialania procesu ale chyba chodzi o sposob liczenia czasu a raczej sledzenia go przez system. Pewnie do celow planowania. Ta funkcja moze zostac przerobiona i uzyta

CHECKPOINT_CPU
zalezna od ARCH. Wola tak naprawde 3 funkcje: save_cpu_regs, save_cpu_debug oraz save_cpu_fpu na parametrach h i t (h - ckpt_hdr_cpu*, t - task_struct*). Funckje wygladaja na dobre do uzycia. Oczywiscie lekkie przerobki trzeba bedzie zrobic.

CHECKPOINT_TASK_OBJS
Tutaj znow kilka funkcji ale obiecujaco to wyglada. Funkcje pilnuja zaleznosci miedzy obiektami w strukturze task_struct. Oto funkcje do przejrzenia: checkpoint_task_creds, checkpoint_task_ns, checkpoint_obj_file_table, checkpoint_obj_mm, checkpoint_obj_fs, checkpoint_obj_sem_undo, checkpoint_obj_sighand, ckpt_obj_lookup_add (sprawdza czy t->sighand musi byc zapisane) oraz czasami zawola checkpoint_obj_signal. Determinuje to zmienna typu int o nazwie first uzyta przy ckpt_obj_lookup_add

CHECKPOINT_TASK_SIGNAL
Trzeba przerobic ale wyglada dobrze.

CHECKPOINT_TASK_CREDS
Wyglada na ok - mozna uzyc

CHECKPOINT_TASK_NS
pomiedzy rcu_real_lock a rcu_read_unlock wolana jest tsk_nsproxy(t), wynik zapisuje w nsproxy (typ struct nsproxy*). Dodatkowo get_nsproxy(nsproxy) - nie wiem co to robi. wlasciwe dane trafiaja do ns_objref poprzez checkpoint_obj(ctx, nsproxy, CKPT_OBJ_NS)

CHECKPOINT_OBJ_FILE_TABLE
zasada prosta: struktura files_struct jest odbierana przez get_files_struct(t). Robiony jest zrzut przez checkpoint_obj(ctx, files <-adres_zwrocony_pezez_get_files_struct, CKPT_OBJ_FILE_TABLE).

CHECKPOINT_OBJ_MM
Analogicznie jak funkcja wyzej, wolamy get_task_mm(t) i zwrocony struct mm_struct* przekazujemy: checkpoint_obj(ctx, mm, CKPT_OBJ_MM), wskaznik struct mm_struct* jest wolany jako parametr mmput(mm) - nie wiem po co...

CHECKPOINT_OBJ_FS
Pomiedzy task_lock(current) a task_unclock(current) wolany jest get_fs_struct na t->fs. Ponownie checkpoint_obj(cts, fs, CKPT_OBJ_FS). W tym przypadku put_fs_struct(t->fs) wystepuje.

CHECKPOINT_OBJ_SEM_UNDO
Ta funkcja jest nawet jeszcze prostsza, jezeli t->sysvsem.undo_list nie jest NULL to wolana jest checkpoint_obj(ctx, ulp, CKPT_OBJ_SEM_UNDO), ulp jest tupy struct sem_undo_list* i dostaje wartosc: ulp = t->sysvsem.undo_list

CHECKPOINT_OBJ_SIGHAND


CKPT_OBJ_LOOKUP_ADD
CHECKPOINT_OBJ_SIGNAL


CHECKPOINT_OBJ

